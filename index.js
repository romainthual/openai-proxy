const express = require('express');
const path = require('path');
const axios = require('axios');
const cors = require('cors');
const indexRouter = require('./routes/index');

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());

// Serve static files (site)
app.use(express.static(path.join(__dirname, 'public')));
app.use('/', indexRouter);

// --- Route proxy OpenAI ---
app.post("/chat", async (req, res) => {
  try {
    const userMessage = req.body.message;

    if (!userMessage) {
      return res.status(400).json({ error: "Message manquant" });
    }

    const response = await axios.post(
      "https://api.openai.com/v1/chat/completions",
      {
        model: "gpt-3.5-turbo",
        messages: [{ role: "user", content: userMessage }],
      },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
        },
      }
    );

    const reply = response.data.choices[0].message.content;
    res.json({ reply });
  } catch (error) {
    console.error("Erreur API OpenAI:", error.response?.data || error.message);
    res.status(500).json({ error: "Erreur lors de l'appel Ã  OpenAI" });
  }
});

// Catch-all 404
app.use((req, res, next) => {
  res.status(404).sendFile(path.join(__dirname, 'views', '404.html'));
});

// Start server
app.listen(PORT, () => {
  console.log(`ðŸš€ Server running at http://localhost:${PORT}/`);
});
